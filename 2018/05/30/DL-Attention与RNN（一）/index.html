<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-CN">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2"/>
<meta name="theme-color" content="#222">












<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />






















<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=6.1.0" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.1.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.1.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.1.0">


  <link rel="mask-icon" href="/images/logo.svg?v=6.1.0" color="#222">









<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '6.1.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="RNN 是深度学习的基础之一，主要用于处理文本、音频和视频等序列数据。RNN 可以将序列归纳成一个高层次的理解，从而进行序列注释（annotate sequences），甚至序列生成（generate new sequences）。 在 RNN 的发展过程中，出现了许多更加强大的变体，比如 LSTM。这些模型在翻译、语音识别和图像描述等许多任务中取得了显著的效果。 本文主要介绍了 4 个新的 RN">
<meta name="keywords" content="深度学习">
<meta property="og:type" content="article">
<meta property="og:title" content="（转载）Attention 与 RNN （一）- 神经图灵机">
<meta property="og:url" content="http://yoursite.com/2018/05/30/DL-Attention与RNN（一）/index.html">
<meta property="og:site_name" content="huay&#39;s Blog">
<meta property="og:description" content="RNN 是深度学习的基础之一，主要用于处理文本、音频和视频等序列数据。RNN 可以将序列归纳成一个高层次的理解，从而进行序列注释（annotate sequences），甚至序列生成（generate new sequences）。 在 RNN 的发展过程中，出现了许多更加强大的变体，比如 LSTM。这些模型在翻译、语音识别和图像描述等许多任务中取得了显著的效果。 本文主要介绍了 4 个新的 RN">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://yoursite.com/images/DL-Attention与RNN/rnn-news.png">
<meta property="og:image" content="http://yoursite.com/images/DL-Attention与RNN/ntm-memory.png">
<meta property="og:image" content="http://yoursite.com/images/DL-Attention与RNN/ntm-read.png">
<meta property="og:image" content="http://yoursite.com/images/DL-Attention与RNN/ntm-read2.png">
<meta property="og:image" content="http://yoursite.com/images/DL-Attention与RNN/ntm-write.png">
<meta property="og:image" content="http://yoursite.com/images/DL-Attention与RNN/ntm-attention.png">
<meta property="og:image" content="http://yoursite.com/images/DL-Attention与RNN/ntm-repeat-exp.png">
<meta property="og:updated_time" content="2018-05-30T13:29:16.675Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="（转载）Attention 与 RNN （一）- 神经图灵机">
<meta name="twitter:description" content="RNN 是深度学习的基础之一，主要用于处理文本、音频和视频等序列数据。RNN 可以将序列归纳成一个高层次的理解，从而进行序列注释（annotate sequences），甚至序列生成（generate new sequences）。 在 RNN 的发展过程中，出现了许多更加强大的变体，比如 LSTM。这些模型在翻译、语音识别和图像描述等许多任务中取得了显著的效果。 本文主要介绍了 4 个新的 RN">
<meta name="twitter:image" content="http://yoursite.com/images/DL-Attention与RNN/rnn-news.png">






  <link rel="canonical" href="http://yoursite.com/2018/05/30/DL-Attention与RNN（一）/"/>



<script type="text/javascript" id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>（转载）Attention 与 RNN （一）- 神经图灵机 | huay's Blog</title>
  









  <noscript>
  <style type="text/css">
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion {
      .logo-line-before i { left: initial; }
      .logo-line-after i { right: initial; }
    }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">huay's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>




<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
          
  
  <li class="menu-item menu-item-home">
    <a href="/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-home"></i> <br />首页</a>
</li>

      
        
        
          
  
  <li class="menu-item menu-item-archives">
    <a href="/archives/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />归档</a>
</li>

      
        
        
          
  
  <li class="menu-item menu-item-about">
    <a href="/about/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-user"></i> <br />关于</a>
</li>

      
        
        
          
  
  <li class="menu-item menu-item-tags">
    <a href="/tags/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />标签</a>
</li>

      

      
      
    </ul>
  

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/30/DL-Attention与RNN（一）/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="huay">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="huay's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">（转载）Attention 与 RNN （一）- 神经图灵机
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
                
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-30T15:21:28+08:00">2018-05-30</time>
            

            
            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>RNN 是深度学习的基础之一，主要用于处理文本、音频和视频等序列数据。RNN 可以将序列归纳成一个高层次的理解，从而进行序列注释（annotate sequences），甚至序列生成（generate new sequences）。</p>
<p>在 RNN 的发展过程中，出现了许多更加强大的变体，比如 LSTM。这些模型在翻译、语音识别和图像描述等许多任务中取得了显著的效果。</p>
<p>本文主要介绍了 4 个新的 RNN 技术，而这 4 个技术都离不开 Attention 机制。</p>
<ul>
<li>Neural Turing Machines (神经图灵机)</li>
<li>Attentional Interfaces</li>
<li>Adaptive Computation Time</li>
<li>Neural Programmer</li>
</ul>
<p><img src="/images/DL-Attention与RNN/rnn-news.png" alt=""></p>
<a id="more"></a>
<hr>
<p>原文地址: <a href="https://distill.pub/2016/augmented-rnns/" target="_blank" rel="noopener">https://distill.pub/2016/augmented-rnns/</a></p>
<h2 id="Neural-Turing-Machines-神经图灵机"><a href="#Neural-Turing-Machines-神经图灵机" class="headerlink" title="Neural Turing Machines (神经图灵机)"></a>Neural Turing Machines (神经图灵机)</h2><p>NTM [2]将 RNN 与一个外部<strong>记忆/内存</strong>模块（external memory bank）组合在一起，而这个记忆模块实际上是一组向量（向量相当于神经网络中的自然语言）。</p>
<p><img src="/images/DL-Attention与RNN/ntm-memory.png" alt=""></p>
<p>既然是一块“内存”，自然存在 Read/Write 两个操作。难点在于如何区分这两个操作（make them differentiable）。具体来说，我们想区分读写的位置（location ），这样就可以学习从哪读取，以及写入到什么位置。因为内存地址本质上是离散化的，因此这个问题比较棘手。</p>
<p>NMT 使用了一个聪明的方法来解决这个问题：它在每一步以<strong>不同的程度</strong>来读/写各个位置。</p>
<h3 id="读取-amp-写入"><a href="#读取-amp-写入" class="headerlink" title="读取 &amp; 写入"></a>读取 &amp; 写入</h3><p>以读取为例，NTM 模型会输出一个<strong>注意力分布（attention distribution）</strong>，来描述我们对不同位置的<strong>关注度</strong>。因此，读取的结果实际上是一个加权和（weighted sum）。</p>
<p>示例 1</p>
<p><img src="/images/DL-Attention与RNN/ntm-read.png" alt=""></p>
<blockquote>
<p>如图所示：此时的 attention 在第二块，因此 memery 中第二块的权重最大，导致最后的输出也完全偏向第二块</p>
</blockquote>
<blockquote>
<p>图中的箭头可以看作是一个矢量；原网站可以通过移动鼠标实现动态效果。</p>
</blockquote>
<p>示例 2</p>
<p><img src="/images/DL-Attention与RNN/ntm-read2.png" alt=""></p>
<blockquote>
<p>这时，attention 在三、四之间，因此，最后的输出可以看作是三、四的矢量和。</p>
</blockquote>
<p>类似的，NTM 每次也会以不同的程度进行写入，而“attention distribution”则描述了写入的权重。Memory 中每个位置的<strong>新值</strong>由旧值与 attention 加权决定。</p>
<p>示例</p>
<p><img src="/images/DL-Attention与RNN/ntm-write.png" alt=""></p>
<blockquote>
<p>如图，待写入的值为（↗）， attention 的旧值为（↘） 它们的矢量和大致等于（→），即 memory 中的新值。（假设这里 $a_i=0.5$）</p>
</blockquote>
<h3 id="Attention-机制"><a href="#Attention-机制" class="headerlink" title="Attention 机制"></a>Attention 机制</h3><p>下一个问题： NTM 是如何决定将注意力集中在记忆中的哪个位置的？</p>
<p>NTM 给出了两种方法：</p>
<ol>
<li>Content-based attention (基于内容的)</li>
<li>Location-based attention (基于位置的)</li>
</ol>
<p>Content-based attention 会让 NTM 遍历它的记忆库，然后关注在与内容相符合的区域；Location-based attention 则允许在记忆区域进行相对移动，使 NTM 可以循环。</p>
<blockquote>
<p>原文：Content-based attention allows NTMs to search through their memory and focus on places that match what they’re looking for, while location-based attention allows relative movement in memory, enabling the NTM to loop.</p>
</blockquote>
<p>图示</p>
<blockquote>
<p>训练初，Memory 是一组待训练的随机向量；这里假设已经处于 fine tuning 的阶段</p>
</blockquote>
<p><img src="/images/DL-Attention与RNN/ntm-attention.png" alt=""></p>
<ol>
<li>首先，对新的 query vector，会计算其与每个内存块的相似度（图中蓝色表示相似，粉色反之）</li>
<li>之后相似度会通过 softmax 转化成 attention 分布（概率化）</li>
<li>对新旧 attention 进行加权求和（图中对当前 attention 给予了更大的权重，通过 interpolation amount 颜色的深浅表示）</li>
<li>对 attention 作卷积（convolve），这允许 ntm 转移它的重点，其中 shift filter 也是可学习的参数</li>
<li>对 attention 作 sharpen （相当于加重当前注意力，图中表现为颜色更深）</li>
</ol>
<p>这种读写的能力使 NTM 具有比普通神经网络更强的表达能力。比如，它可以学习记忆一段长序列，然后不断地循环重复。此时，我们能观测到它的读写位置，以便更全面地理解其工作原理。它们还能学习模仿查询表，甚至学习对数字排序。但是，它们却无法完成许多基本任务，比如加法或者乘法运算。</p>
<p><img src="/images/DL-Attention与RNN/ntm-repeat-exp.png" alt=""></p>
<blockquote>
<p>[2] 中的 Repeat Copy 实验，文中还介绍了其他相关实验</p>
</blockquote>
<h3 id="研究进展"><a href="#研究进展" class="headerlink" title="研究进展"></a>研究进展</h3><p>自最初的神经图灵机论文发表后，在这一领域涌现出了大量优质论文。神经GPU (<a href="http://arxiv.org/pdf/1511.08228.pdf" target="_blank" rel="noopener">Kaiser &amp; Sutskever, 2015</a>) 克服了神经图灵机器无法计算加法和乘法的缺陷。<a href="http://arxiv.org/pdf/1505.00521.pdf" target="_blank" rel="noopener">Zaremba &amp; Sutskever, 2016</a> 采用强化学习的方法训练 NTM。Neural Random Access Machines (<a href="http://arxiv.org/pdf/1511.06392.pdf" target="_blank" rel="noopener">Kurach et al., 2015</a>) 基于指针运行。一些论文尝试了不同的数据结构，比如堆栈和队列 (<a href="http://papers.nips.cc/paper/5648-learning-to-transduce-with-unbounded-memory.pdf" target="_blank" rel="noopener">Grefenstette et al. 2015</a>; <a href="https://arxiv.org/pdf/1503.01007.pdf" target="_blank" rel="noopener">Joulin &amp; Mikolov, 2015</a>)。记忆网络(<a href="http://arxiv.org/abs/1410.3916" target="_blank" rel="noopener">Weston et al., 2014</a>; <a href="http://arxiv.org/abs/1506.07285" target="_blank" rel="noopener">Kumar et al., 2015</a>) 是解决类似问题的另一种方式。</p>
<h3 id="实现（Code）"><a href="#实现（Code）" class="headerlink" title="实现（Code）"></a>实现（Code）</h3><ul>
<li><p>神经图灵机（NTM）</p>
<ul>
<li>carpedm20/<a href="https://github.com/carpedm20/NTM-tensorflow" target="_blank" rel="noopener">NTM-tensorflow</a></li>
<li>kaishengtai/<a href="https://github.com/kaishengtai/torch-ntm" target="_blank" rel="noopener">torch-ntm</a></li>
</ul>
</li>
<li><p>神经GPU</p>
<ul>
<li><a href="https://github.com/tensorflow/models/tree/master/research/neural_gpu" target="_blank" rel="noopener">https://github.com/tensorflow/models/tree/master/research/neural_gpu</a></li>
</ul>
</li>
<li><p>记忆网络</p>
<ul>
<li>carpedm20/<a href="https://github.com/carpedm20/MemN2N-tensorflow" target="_blank" rel="noopener">MemN2N-tensorflow</a></li>
</ul>
</li>
</ul>
<blockquote>
<p>其他语言或框架的版本可以去原文查看，这里只记录了比较流行的版本</p>
</blockquote>
<h2 id="小结（非原文）"><a href="#小结（非原文）" class="headerlink" title="小结（非原文）"></a>小结（非原文）</h2><p>神经图灵机很好的描述了 Attention 的作用和效果（配合原文提供的动画演示）。它为下面要介绍几项 RNN 技术改进提供了重要的思想。</p>
<p>简单来说，Attention 机制实际上就是<strong>学习</strong>一个权重分布，再将该权重分布重新施加到原来的特征/输入之上。不同的 Attention 都是基于这个思想，然后对细节进行了改进。</p>
<blockquote>
<p>目前主流的attention方法都有哪些？ - 知乎 - <a href="https://www.zhihu.com/question/68482809/answer/264070398" target="_blank" rel="noopener">Jason Zhao 的回答</a></p>
</blockquote>
<p>（待续…）</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1]. <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="noopener">Understanding LSTM Networks</a> – colah’s blog</p>
<p>[2]. Alex Graves, Greg Wayne, Ivo Danihelka. <a href="https://arxiv.org/abs/1410.5401" target="_blank" rel="noopener">Neural Turing Machines</a></p>
<p>翻译参考</p>
<ul>
<li><a href="https://blog.csdn.net/mmc2015/article/details/55000814" target="_blank" rel="noopener">RNN的四种变形：Attention and Augmented Recurrent Neural Networks【译文】</a> - CSDN博客 </li>
</ul>

      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/深度学习/" rel="tag"># 深度学习</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/05/26/hello-my-bolg/" rel="next" title="Hello! My Blog">
                <i class="fa fa-chevron-left"></i> Hello! My Blog
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/05/30/DL-Attention与RNN（二）/" rel="prev" title="DL-Attention与增强RNNs（二）">
                DL-Attention与增强RNNs（二） <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.jpg"
                alt="huay" />
            
              <p class="site-author-name" itemprop="name">huay</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">41</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">22</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  <a href="https://github.com/imhuay" target="_blank" title="GitHub"><i class="fa fa-fw fa-github"></i></a>
                  
                </span>
              
                <span class="links-of-author-item">
                  <a href="mailto:imhuay@163.com" target="_blank" title="E-Mail"><i class="fa fa-fw fa-envelope"></i></a>
                  
                </span>
              
                <span class="links-of-author-item">
                  <a href="https://www.kaggle.com/imhuay/kernels" target="_blank" title="Kaggle"><i class="fa fa-fw fa-cubes"></i></a>
                  
                </span>
              
                <span class="links-of-author-item">
                  <a href="https://stackoverflow.com/users/8000475/imhuay" target="_blank" title="StackOverflow"><i class="fa fa-fw fa-stack-overflow"></i></a>
                  
                </span>
              
                <span class="links-of-author-item">
                  <a href="https://www.nowcoder.com/profile/5608104" target="_blank" title="牛客"><i class="fa fa-fw fa-vk"></i></a>
                  
                </span>
              
            </div>
          

          
          

          
          

          
            
          
          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Neural-Turing-Machines-神经图灵机"><span class="nav-number">1.</span> <span class="nav-text">Neural Turing Machines (神经图灵机)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#读取-amp-写入"><span class="nav-number">1.1.</span> <span class="nav-text">读取 &amp; 写入</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Attention-机制"><span class="nav-number">1.2.</span> <span class="nav-text">Attention 机制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#研究进展"><span class="nav-number">1.3.</span> <span class="nav-text">研究进展</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#实现（Code）"><span class="nav-number">1.4.</span> <span class="nav-text">实现（Code）</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#小结（非原文）"><span class="nav-number">2.</span> <span class="nav-text">小结（非原文）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Reference"><span class="nav-number">3.</span> <span class="nav-text">Reference</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">huay</span>

  

  
</div>




  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动 v3.6.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/theme-next/hexo-theme-next">NexT.Gemini</a> v6.1.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>














  













  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=6.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=6.1.0"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=6.1.0"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=6.1.0"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=6.1.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=6.1.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.1.0"></script>



  



	





  





  










  





  

  

  

  
  

  
  

  


  
  

  

  

  

  

</body>
</html>
